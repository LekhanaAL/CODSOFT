{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182b83c0-34e3-473e-b8bc-13d7205d9584",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lekhanaal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lekhanaal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "import gc\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Stopwords set\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Text preprocessing function with re module\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        # Remove punctuation and numbers\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        # Tokenize (split by whitespace)\n",
    "        words = word_tokenize(text)\n",
    "        # Remove stopwords\n",
    "        words = [word for word in words if word not in stop_words]\n",
    "        return ' '.join(words)\n",
    "    else:\n",
    "        return ''  # Return empty string if input is not a string\n",
    "\n",
    "# Load datasets\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "solution_df = pd.read_csv('solution.csv')\n",
    "\n",
    "# Fill missing values\n",
    "train_df.fillna('', inplace=True)\n",
    "test_df.fillna('', inplace=True)\n",
    "solution_df.fillna('', inplace=True)\n",
    "\n",
    "# Preprocess the descriptions\n",
    "train_df['DESCRIPTION'] = train_df['DESCRIPTION'].astype(str).apply(preprocess_text)\n",
    "test_df['DESCRIPTION'] = test_df['DESCRIPTION'].astype(str).apply(preprocess_text)\n",
    "solution_df['DESCRIPTION'] = solution_df['DESCRIPTION'].astype(str).apply(preprocess_text)\n",
    "\n",
    "# TF-IDF vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "X_train_text = tfidf_vectorizer.fit_transform(train_df['DESCRIPTION'])\n",
    "X_test_text = tfidf_vectorizer.transform(test_df['DESCRIPTION'])\n",
    "X_solution_text = tfidf_vectorizer.transform(solution_df['DESCRIPTION'])\n",
    "\n",
    "# Combine TF-IDF features with other features\n",
    "X_train = X_train_text\n",
    "X_test = X_test_text\n",
    "X_solution = X_solution_text\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(train_df['GENRE'])\n",
    "y_test = le.transform(solution_df['GENRE'])\n",
    "\n",
    "# Apply SMOTE to handle class imbalance\n",
    "smote = SMOTE(random_state=52)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Reduce dimensionality using PCA\n",
    "pca = PCA(n_components=500)\n",
    "X_train_res = pca.fit_transform(X_train_res.toarray())\n",
    "X_test_reduced = pca.transform(X_test.toarray())\n",
    "X_solution_reduced = pca.transform(X_solution.toarray())\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(model, X_test, y_true):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Train and evaluate Naive Bayes classifier\n",
    "param_grid_nb = {'alpha': [0.1, 0.5, 1.0]}\n",
    "grid_search_nb = GridSearchCV(MultinomialNB(), param_grid_nb, cv=5, scoring='accuracy')\n",
    "grid_search_nb.fit(X_train_res, y_train_res)\n",
    "nb_model = grid_search_nb.best_estimator_\n",
    "joblib.dump(nb_model, 'naive_bayes_model.pkl')\n",
    "nb_accuracy, nb_precision, nb_recall, nb_f1 = evaluate_model(nb_model, X_test_reduced, y_test)\n",
    "\n",
    "# Train and evaluate Logistic Regression classifier\n",
    "param_grid_lr = {'C': [0.1, 1, 10], 'solver': ['liblinear', 'saga']}\n",
    "grid_search_lr = GridSearchCV(LogisticRegression(max_iter=1000), param_grid_lr, cv=5, scoring='accuracy')\n",
    "grid_search_lr.fit(X_train_res, y_train_res)\n",
    "lr_model = grid_search_lr.best_estimator_\n",
    "joblib.dump(lr_model, 'logistic_regression_model.pkl')\n",
    "lr_accuracy, lr_precision, lr_recall, lr_f1 = evaluate_model(lr_model, X_test_reduced, y_test)\n",
    "\n",
    "# Train and evaluate SVM classifier\n",
    "param_grid_svm = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "grid_search_svm = GridSearchCV(SVC(), param_grid_svm, cv=5, scoring='accuracy')\n",
    "grid_search_svm.fit(X_train_res, y_train_res)\n",
    "svm_model = grid_search_svm.best_estimator_\n",
    "joblib.dump(svm_model, 'svm_model.pkl')\n",
    "svm_accuracy, svm_precision, svm_recall, svm_f1 = evaluate_model(svm_model, X_test_reduced, y_test)\n",
    "\n",
    "# Save the TF-IDF vectorizer and label encoder\n",
    "joblib.dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')\n",
    "joblib.dump(le, 'label_encoder.pkl')\n",
    "\n",
    "# Print evaluation results\n",
    "print(f\"Naive Bayes - Accuracy: {nb_accuracy}, Precision: {nb_precision}, Recall: {nb_recall}, F1-score: {nb_f1}\")\n",
    "print(f\"Logistic Regression - Accuracy: {lr_accuracy}, Precision: {lr_precision}, Recall: {lr_recall}, F1-score: {lr_f1}\")\n",
    "print(f\"SVM - Accuracy: {svm_accuracy}, Precision: {svm_precision}, Recall: {svm_recall}, F1-score: {svm_f1}\")\n",
    "\n",
    "# Predict genre for a new plot summary\n",
    "def predict_genre(model, plot_summary):\n",
    "    plot_summary_preprocessed = preprocess_text(plot_summary)\n",
    "    plot_summary_tfidf = tfidf_vectorizer.transform([plot_summary_preprocessed])\n",
    "    plot_summary_reduced = pca.transform(plot_summary_tfidf.toarray())\n",
    "    predicted_genre = model.predict(plot_summary_reduced)\n",
    "    return le.inverse_transform(predicted_genre)[0]\n",
    "\n",
    "# Example usage\n",
    "new_plot_summary = \"A young boy discovers he has magical powers and attends a school for wizards.\"\n",
    "predicted_genre_nb = predict_genre(nb_model, new_plot_summary)\n",
    "predicted_genre_lr = predict_genre(lr_model, new_plot_summary)\n",
    "predicted_genre_svm = predict_genre(svm_model, new_plot_summary)\n",
    "\n",
    "print(f\"Predicted genre (Naive Bayes): {predicted_genre_nb}\")\n",
    "print(f\"Predicted genre (Logistic Regression): {predicted_genre_lr}\")\n",
    "print(f\"Predicted genre (SVM): {predicted_genre_svm}\")\n",
    "\n",
    "# Free up memory\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ecfecf-860e-4cfd-a968-2bb3c5752e65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
